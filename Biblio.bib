@Article{Bimbot2004,
author="Bimbot, Fr{\'e}d{\'e}ric
and Bonastre, Jean-Fran{\c{c}}ois
and Fredouille, Corinne
and Gravier, Guillaume
and Magrin-Chagnolleau, Ivan
and Meignier, Sylvain
and Merlin, Teva
and Ortega-Garc{\'i}a, Javier
and Petrovska-Delacr{\'e}taz, Dijana
and Reynolds, Douglas A.",
title="A Tutorial on Text-Independent Speaker Verification",
journal="EURASIP Journal on Advances in Signal Processing",
year="2004",
volume="2004",
number="4",
pages="101962",
abstract="This paper presents an overview of a state-of-the-art text-independent speaker verification system. First, an introduction proposes a modular scheme of the training and test phases of a speaker verification system. Then, the most commonly speech parameterization used in speaker verification, namely, cepstral analysis, is detailed. Gaussian mixture modeling, which is the speaker modeling technique used in most systems, is then explained. A few speaker modeling alternatives, namely, neural networks and support vector machines, are mentioned. Normalization of scores is then explained, as this is a very important step to deal with real-world data. The evaluation of a speaker verification system is then detailed, and the detection error trade-off (DET) curve is explained. Several extensions of speaker verification are then enumerated, including speaker tracking and segmentation by speakers. Then, some applications of speaker verification are proposed, including on-site applications, remote applications, applications relative to structuring audio information, and games. Issues concerning the forensic area are then recalled, as we believe it is very important to inform people about the actual performance and limitations of speaker verification systems. This paper concludes by giving a few research trends in speaker verification for the next couple of years.",
issn="1687-6180",
doi="10.1155/S1110865704310024",
url="http://dx.doi.org/10.1155/S1110865704310024"
}

@inproceedings{vukotic:hal-01314302,
  TITLE = {{Bidirectional Joint Representation Learning with Symmetrical Deep Neural Networks for Multimodal and Crossmodal Applications}},
  AUTHOR = {Vukotic, Vedran and Raymond, Christian and Gravier, Guillaume},
  URL = {https://hal.inria.fr/hal-01314302},
  BOOKTITLE = {{ICMR}},
  ADDRESS = {New York, United States},
  ORGANIZATION = {{ACM}},
  YEAR = {2016},
  MONTH = Jun,
  KEYWORDS = {neural networks ; deep learning ; representation ; embedding ; multimodal ; crossmodal ; retrieval ; video retrieval ; video hyperlinking ; image and text ; autoencoder ; bidirectional learning ; tied weights ; shared weights},
  PDF = {https://hal.inria.fr/hal-01314302/file/vukotic_BiDNN.pdf},
  HAL_ID = {hal-01314302},
  HAL_VERSION = {v1},
}

@article{DBLP:journals/corr/GhahabiH15,
  author    = {Omid Ghahabi and
               Javier Hernando},
  title     = {Deep Learning for Single and Multi-Session i-Vector Speaker Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.02560},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.02560},
  timestamp = {Sat, 02 Jan 2016 11:38:49 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/GhahabiH15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{ghahabi2014deep,
  title={Deep belief networks for i-vector based speaker recognition},
  author={Ghahabi, Omid and Hernando, Javier},
  booktitle={2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1700--1704},
  year={2014},
  organization={IEEE}
}

@inproceedings{bordes2012joint,
  title={Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing.},
  author={Bordes, Antoine and Glorot, Xavier and Weston, Jason and Bengio, Yoshua},
  booktitle={AISTATS},
  volume={351},
  pages={423--424},
  year={2012}
}

@article{DBLP:journals/corr/SaonSRK16,
  author    = {George Saon and
               Tom Sercu and
               Steven J. Rennie and
               Hong{-}Kwang Jeff Kuo},
  title     = {The {IBM} 2016 English Conversational Telephone Speech Recognition
               System},
  journal   = {CoRR},
  volume    = {abs/1604.08242},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.08242},
  timestamp = {Mon, 02 May 2016 18:22:52 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/SaonSRK16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{richardson2015deep,
  title={Deep neural network approaches to speaker and language recognition},
  author={Richardson, Fred and Reynolds, Douglas and Dehak, Najim},
  journal={IEEE Signal Processing Letters},
  volume={22},
  number={10},
  pages={1671--1675},
  year={2015},
  publisher={IEEE}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={IEEE}
}


@article {Hinton504,
	author = {Hinton, G. E. and Salakhutdinov, R. R.},
	title = {Reducing the Dimensionality of Data with Neural Networks},
	volume = {313},
	number = {5786},
	pages = {504--507},
	year = {2006},
	doi = {10.1126/science.1127647},
	publisher = {American Association for the Advancement of Science},
	abstract = {High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such {\textquotedblleft}autoencoder{\textquotedblright} networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.},
	issn = {0036-8075},
	URL = {http://science.sciencemag.org/content/313/5786/504},
	eprint = {http://science.sciencemag.org/content/313/5786/504.full.pdf},
	journal = {Science}
}
