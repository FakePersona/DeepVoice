\documentclass[conference]{IEEEtran}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{fullpage}
\usepackage[french]{babel}
\usepackage{graphicx}

\title{PROJ: DeepVoice}

\author{Rémi Hutin \and Rémy Sun \and Raphael Truffet}

\begin{document}

\maketitle

\section{Introduction}

\section{Sound signals}

\subsection{Cepstral analysis}

The speech signal of a locutor is hardly suitable for statistical modeling or the calculation of a distance.
In order to obtain a representation which is more compact and less redundant, we use a cepstral representation of the speech.

The cepstrum of a signal $x(t)$ is defined by :

$$C(x(t)) = F^{-1}(\ln(|F(x(t))|)$$

\subsection{GMMs}

\subsection{Supervectors and i-vectors}

\subsection{Previous works}

\section{Use of neuronal networks}

\subsection{Formal neuron}

\paragraph{Neuron?}
A neuron can be thought of as a function which takes an $n$-dimensional vector $A$ as input and returns a scalar $e$ as output. This function typically has two internal parameters which are a bias $b$ and a weight-matrix $W$. The function starts by calculating $WA+b$ before using a non-linear activation function (such as sigmoid or tanh): $e=f(WA+b)$.

\paragraph{Adjusting the function}
Our endgoal is to have the neuron, and by extension the neural network, perform
a certain task. The formal neuron \og learns\fg by adjusting its function to perform better on
this designated task. For simplicity's sake, we will first explain how this
process - called \og backpropagation\fg{} - works with a single neuron.

For instance, suppose we have a bi-dimensional vector given as input and that we
want our neuron to return 1 if its two coordinates are the identical and -1 if
it is not. A natural way to evaluate how accurate our neuron is by looking at the
distance between its output $e$ and the desired result r : d(e)=|e-r|.

We want to modify our neuron/function to minimize this distance. That means
changing $e$, typically by gradient descent on function $d$ derivative. Here,
$\frac{\partial d}{\partial e} = r-e$, which means we want to \og move\fg{} $e$ in this
direction. To this end, we modify our function's two internal parameters $W$ and
$b$. $e$, and by extension $d$, can actually be seen as a function of those two
parameters: $d(W,b)=|e(W,b)-r|$. Therefore $\frac{\partial d}{\partial W}
   = \frac{\partial d}{\partial e}\frac{\partial e}{\partial W}$,
$\frac{\partial d}{\partial b}
   = \frac{\partial d}{\partial e}\frac{\partial e}{\partial b}$. We then only
   need to compute new internal parameters $W'$ and $b'$ with 

\begin{equation}
     W'=W + s\frac{\partial d}{\partial W}=W-s\frac{\partial d}{\partial e}\frac{\partial e}{\partial W}
\end{equation}

\begin{equation}
     b'=b + s\frac{\partial d}{\partial b}=b-s\frac{\partial d}{\partial e}\frac{\partial e}{\partial b}
\end{equation}

What we just demonstrated was a simple backpropagation algorithm called gradient
descent. This method is deeply flawed, but most state of the art backpropagation
methods find their origins in this humble algorithm.

\paragraph{Neuronal network?}

Typically, a neural \textbf{network} is made up of more than a single neuron. A
neural layer refers to multiple neurons working on the same input (or parts of
the same input) and producing an output that can be construed as some form of
concatenation of their respective outputs. This output can be in turn regarded
as an alternate representation of the input. Backpropagation for each neuron
works the same way as it would if it were the only neuron calculating.

The notion of \textbf{deep} learning comes from the fact that the alternate
reprensentation computed by one layer $A$ can be fed as input to another layer $B$.
This allows networks to infer multiple levels of representation, same as one
first processes simple geometrical forms before recognizing more complex
compositions. Backpropagation is straight-forwardly computed on layer $B$. It is
computed on layer $A$ by looking at $\frac{\partial d}{\partial input_B}$
instead of $\frac{\partial d}{\partial e}$
\subsection{Autoencoders}

An autoencoder is a neuronal network with a particular architecture which is defined below.

\paragraph{A default goal}
Basically, in order to learn a neuronal network, we need to affect to each input of the learning set a label, that is the output we want to enclose, the desired result. However, autoencoders bypass this need by defaulting to an objective that does not require additional information on the input. In fact, the desired result is the input itself.

\paragraph{Structure}
A neuronal network that tries to reconstruct the input may learn the identity. But an autoencoder has a structure the makes it impossible. In fact, an autoencoder has at least one hidden layer that is smaller than the input. So an autoencoder can be decomposed as an encoder that transform the input to a smaller represatation, called latent representation or code, and a decoder that reconstruct the input from the latent representation.

\begin{figure}[!h]
    \centering
    \caption{Structure of an autoencoder}
    \includegraphics[width=7cm]{Autoencoder_structure.png}
    \label{autoencoder_structure}
\end{figure}


\paragraph{Why use autoencoders?}

Autoencoders can be used for denoising, using corrupted data as input and the original data as objective.

Autoencoders may also be very useful to learn a representation. In fact, the latent represention contains enough information to reconstruct the data.

In our context, autoencoders could be used to find a representation of a speaker, by giving to the autoencoder a i-vector from a speaker as input, and an another i-vector from the same speaker as objective. This idea is based on considerating the within-speaker variability as a noise, and using a denoising autoencoder. Repeating this with several pairs of i-vectors, we may learn a representation of the speaker. 

Since the problem is symmetrical, we can perform the learning in both directions. One way to perform this training is to use an autoencoder

\subsection{Tied weight autoencoder}

\paragraph{Architecture}
[Explanation]

\paragraph{Good results}
[Vedran's paper?]

\section{Method}




\end{document}
